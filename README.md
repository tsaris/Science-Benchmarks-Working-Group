## Overview and objective: 
The working group’s goal is to assemble and distribute scientific data sets relevant to a scientific campaign in a systematic manner, and pose quantifiable targets (“science benchmark”). A benchmark involves (i) a data set, (ii) objective criteria to meet, and (iii) a reference implementation. The objective criteria depends on the scientific problem at hand. The metric should be well defined on the data but could come from a diverse set of measures (one or more of: accuracy targets, top-1 or 5% error, time to convergence, cross-validation rates, confusion matrices, type-1/type-2 error rates, inference times, surrogate accuracy, control stability measure, etc.).

## Benchmarks
1. CloudMask
2. STEMDL: [Data](https://doi.ccs.ornl.gov/ui/doi/70), [code](https://github.com/at-aaims/stemdl-benchmark)
3. CANDLE-UNO 

## Reference Implementation: 
The reference implementation is primarily to demonstrate feasibility, show how the data is represented, help address any interpretation considerations, and potentially trigger initial ideas on how the benchmark can be improved.

## Respondents: 
At the present time, we expect respondents to submit the results of their run, and should provide justification in the form of documentation (e.g., a technical manuscript or source code with run instructions). We are exploring setting this up as a “pull request” based contribution mechanism.

<img width="717" alt="Screen Shot 2021-06-23 at 3 49 56 PM" src="https://user-images.githubusercontent.com/24704023/123159172-b08aa500-d43a-11eb-99f4-61c4193d5e69.png">
